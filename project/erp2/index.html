<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Processing speech sounds in speech(-like) perception: an ERP study.</title>
        <style>

    html body {
        font-family: 'Lora', sans-serif;
        background-color: #FFFDF8;
    }

    :root {
        --accent: #1F1F1F;
        --border-width:  0 ;
    }

</style>


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=VT323">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/lakeside-light.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">


<link rel="stylesheet" href="https://mcanzi.github.io/css/main.css">




 


    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>
    

    <script>hljs.initHighlightingOnLoad();</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link href="https://gitcdn.github.io/bootstrap-toggle/2.2.2/css/bootstrap-toggle.min.css" rel="stylesheet">
<script src="https://gitcdn.github.io/bootstrap-toggle/2.2.2/js/bootstrap-toggle.min.js"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>


<script>
$(document).ready(function(){
    
  var input = $('#night-mode-toggle');
  var container = $('#bigbody');
  var stat = $('#button-status');
  
  container.toggleClass(localStorage.toggled);
  stat.bootstrapToggle(localStorage.button).change();
  
  input.on('click', function() {
      if (localStorage.toggled != "-nightmode" ) {
          container.toggleClass("-nightmode", true );
          localStorage.toggled = "-nightmode";
          localStorage.button = "on";
       } else {
          container.toggleClass("-nightmode", false );
          localStorage.toggled = "";
          localStorage.button = "off"
       }
  })
});
</script>
 <meta name="generator" content="Hugo 0.58.3" />
        
        

    
    <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
    <link rel="manifest" href="/img/favicon/site.webmanifest">
    <link rel="mask-icon" href="/img/favicon/safari-pinned-tab.svg" color="#000000">
    <link rel="shortcut icon" href="/img/favicon/favicon.ico">
    <meta name="msapplication-TileColor" content="#2b5797">
    <meta name="msapplication-config" content="/img/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    
    
    
    <meta property="og:title" content="Processing speech sounds in speech(-like) perception: an ERP study.">
    <meta property="og:type" content="article">
      
      <meta name="twitter:card" content="summary">
      <meta name="twitter:image" content="https://mcanzi.github.io/favicon/mcanzi.png" >
      
    <meta property="description" content="Experiment">
    <meta property="og:description" content="Experiment">
    
    <meta name="twitter:creator" content="">
    <meta name="twitter:site" content="">
    
    </head>

    
    
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    

    <body id = "bigbody">
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">Processing speech sounds in speech(-like) perception: an ERP study.</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">home</a></li>
                            
                                <li><a href="/posts/">blog</a></li>
                            
                                <li><a href="/post/">curriculum vitae</a></li>
                            
                                <li><a href="/project/">selected presentations and research</a></li>
                            
                                <li><a href="/tags/">tags</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:massimiliano.canzi@manchester.ac.uk"><i class="fa fa-envelope-o"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/mcanzi"><i class="fa fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://twitter.com/mc_anzi/"><i class="fa fa-twitter"></i></a></li>
                            
                            <li id="night-mode-toggle">
    <input type="checkbox" id = "button-status"
        data-toggle="toggle"
        data-width = "10"
        data-height = "1"
        data-on="<i class='fa fa-moon-o fa-lg' style='vertical-align:25%'></i>"
        data-off= "<i class='fa fa-sun-o fa-lg' style='vertical-align:25%'></i>"
        data-style="ios"
        data-onstyle = "default">
</li>
                        </ul>
                    
                </div>
            </div>
        </nav>


<main>

    <div class="item">

    
    
    

    
      
      
    

    <h4><a href="/project/erp2/">Processing speech sounds in speech(-like) perception: an ERP study.</a></h4>
    <h5>November 25, 2019 - 4 minutes</h5>
    <h5>Experiment</h5>

    
    
    <a href="/tags/erp">
        <kbd class="item-tag"> erp </kbd>
    </a>
    
    <a href="/tags/perception">
        <kbd class="item-tag"> perception </kbd>
    </a>
    

</div>


    <br> <div class="text-justify"><p>The aim of our study is to investigate whether phonetic and phonological information are processed earlier in the brain compared to semantic information in speech perception. ERP components found at different times following the presentation of a speech or speech-like stimulus have been linked to the processing of different components of the speech signal (e.g. phonetic, semantic or syntactic information). Understanding the nature of ERP components involved in the processing of speech and, in particular, understanding their timing can be extremely useful in defining the structure of an architecture of speech perception and, in more general terms, of grammar. While the N400 ERP component, found approximately 400 ms after the presentation of a stimulusâ€™ onset has been extensively linked to semantic mismatch processing by the brain (Kutas and Hillyard 1984), the nature of some pre-N400 effects is still unclear. The phonological mismatch negativity (PMN) component has been argued to be connected to phonological/sound processing and mismatch in perception (Connolly and Philips 1994). However, evidence on this phenomenon is scarce and contradictory at times. We devised an experiment that aims at isolating sound processing in the speech signal from other layers of information (e.g. semantic or syntactic) in order to study which pre-N400 components are present, with a particular focus on the PMN, when processing speech-like information in absence of lexical activation.</p>

<p>In our experiment, 20 (F = 12) native English speakers were instructed to recognise and remember two pairs of trisyllabic (CVCVCV) nonce words, synthesised in Praat and controlled for vowel length, word length and pitch contour. The transitional probability between the two items of each pair was 1. Following a computerised learning phase, participants were presented with a testing block where they were asked to distinguish between nonce-word pairs that they had previously learnt and manipulated pairs. In the final phase of the experiment, a passive listening task was administered to all participants. During this phase, the nonce-word pairs were presented as learnt to all participants 75% of the time. However, the first syllable of the second nonce word of each pair was changed 25% of the time to elicit mismatch between expectations, caused by the high transitional probability between the two items of each pair, and the stimuli presented. EEG signal was recorded throughout this phase by 64 high-impedance electrodes placed on the scalp. Average ERPs were calculated for both conditions (control vs manipulated/target stimuli). The averaged ERP data for all participants were later analysed in R.</p>

<p>Figure 1 shows the control-target effect curve at one scalp site (FC4). The red lines represent the portions of the curve where a significant difference between the two conditions is present (p &lt; 0.05). Significance has been tested using an adaptive factor adjustment (AFA) method (Sheu, Perthame, Lee, and Causeur 2016). No significant N400 effect is present across all scalp sites. This is to be expected based on the nature of the stimuli, designed precisely to avoid lexical activation. A positive shift in potential is present for the target condition at approximately 300 ms throughout most scalp sites. This effect can be connected to the P3 component, linked to stimulus categorisation and the presentation of oddball stimuli. Manipulated stimuli are more likely to elicit a greater P3 response as they are presented at a much lower rate than control ones. Some small negative effects at around 100-150 ms (mismatch negativity) are commonly linked to low-level perception of mismatching sound stimuli, for the target condition. Ultimately, no negative shift in electrical potential is present for the target condition at around 250 ms (PMN) post stimulus onset. Several hypotheses can be put forward to account for the absence of the PMN component, with the main theory being that the component indeed reflects a more abstract, semantic level of processing. On the other hand, the passive nature of the listening task - usually linked to smaller effects in ERP experiments (Astheimer and Sanders 2011) - could mean that some of the effects were lost to bigger shifts in potential (such as to the P3). Further experiments that incorporate active, behavioural tasks with a similar experimental paradigm are being run to study the effects of attention (i.e. passive vs active listening) to determine whether some pre-N400 components, such as the PMN, while being phonetic in nature might still require a higher level of processing compared to more immediate responses such as the mismatch negativity component.</p>

<p><center><img src="/project/erp2_files/Screenshot 2019-11-26 at 11.08.20.png" alt="" /></center></p>

<p>Connolly, J. F., &amp; Phillips, N. A. (1994). Event-related potential components reflect phonological and semantic processing of the terminal word of spoken sentences. Journal of cognitive neuroscience, 6(3), 256-266.</p>

<p>Kutas, M., &amp; Hillyard, S. A. (1984). Brain potentials during reading reflect word expectancy and semantic association. Nature, 307(5947), 161.</p>

<p>Sheu, C. F., Perthame, E., Lee, Y. S., &amp; Causeur, D. (2016). Accounting for time dependence in large-scale multiple testing of event-related potential data. The Annals of Applied Statistics, 10(1), 219-245.</p>
</div>

    
    

    

        <h4 class="page-header">Related</h4>

         <div class="item">

    
    
    

    
    
      
    

    <h4><a href="/2017/09/22/academic-skills/">academic skills</a></h4>
    <h5>September 22, 2017 - 9 minutes</h5>
    <h5></h5>

    
    
    <a href="/tags/r">
        <kbd class="item-tag"> r </kbd>
    </a>
    
    <a href="/tags/praat">
        <kbd class="item-tag"> praat </kbd>
    </a>
    
    <a href="/tags/matlab">
        <kbd class="item-tag"> matlab </kbd>
    </a>
    
    <a href="/tags/erp">
        <kbd class="item-tag"> erp </kbd>
    </a>
    
    <a href="/tags/ggplot">
        <kbd class="item-tag"> ggplot </kbd>
    </a>
    

</div>
 

    

    

</main>

        <footer id = "bigfooter">
            <div style = "padding:15px;">
                <p>Powered by <a href="https://gohugo.io">Hugo</a>. Themed by <a href="https://github.com/nathancday/min_night">min_night</a>.
                </p>
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/"
                title="Creative Commons Attribution 4.0 International license">
                <i class="fa fa-creative-commons" aria-hidden="true"></i> Attribution 4.0 International license
                </a>
            </div>
        </footer>
        
        <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());
          gtag('config', '');
        </script>
       
    </body>

</html>

